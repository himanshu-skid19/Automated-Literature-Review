# Multimodal-RAG-QA

This project aims to integrate multiple data modalities to enhance the accuracy and contextuality of responses in AI-driven QA systems.

## Project Overview
This system uses a novel approach by combining text and visual information to process user queries more effectively. By leveraging advances in AI and machine learning, we provide richer, more accurate answers that integrate seamlessly into various applications.

## Features
- **Multimodal Data Integration:** Utilizes both text and image data for comprehensive query understanding.
- **Advanced RAG Techniques:** Employs state-of-the-art Retriever-Augmented Generation models to enhance answer quality.
- **Wide Application Range:** From educational tools to customer service enhancements, this system is versatile.

## Getting Started
To get started with this project, clone this repository and follow the setup instructions below.

### Prerequisites
- Python 3.8+
- PyTorch 1.7+
- Datasets from [link to datasets]

### Installation
```bash
git clone https://github.com/himanshu-skid19/Multimodal-RAG-QA.git
cd Multimodal-RAG-QA
pip install -r requirements.txt
```

# Team Members:

1. Himanshu Singhal - [@himanshu-skid19](https://github.com/himanshu-skid19)
2. Anushka Gupta - [@anushkacodez](https://github.com/anushkacodez)
3. Atul Jha - [@Atul-04](https://github.com/Atul-04)
4. Parth Agarwal - [@Parth-Agarwal216](https://github.com/Parth-Agarwal216)
